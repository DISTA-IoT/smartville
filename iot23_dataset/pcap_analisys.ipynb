{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcap_splitter.splitter import PcapSplitter\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import zat\n",
    "import shutil\n",
    "\n",
    "from zat.log_to_dataframe import LogToDataFrame\n",
    "import numpy as np\n",
    "from scapy.all import rdpcap\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            file_list.append(filename)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "\n",
    "def extract_5_tuple(pcap_file):\n",
    "    tuples = set()  # Using a set to ensure unique tuples\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            tuples.add(tuple_info)\n",
    "\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def extract_fist_useful_tuple(pcap_file, useful_ip):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    # print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            if not hasattr(transport_layer, 'sport'):\n",
    "                continue\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            if src_ip == useful_ip:\n",
    "                return tuple_info\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def move_files(file_list, source_folder, destination_folder):\n",
    "    for file_name in file_list:\n",
    "        source_file = os.path.join(source_folder, file_name)\n",
    "        destination_file = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.move(source_file, destination_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: {file_name} not found in {source_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while moving {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good to print out versions of stuff\n",
    "print('zat: {:s}'.format(zat.__version__))\n",
    "print('Pandas: {:s}'.format(pd.__version__))\n",
    "print('Numpy: {:s}'.format(np.__version__))\n",
    "print('Scikit Learn Version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting by flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1692.89s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started...\n",
      "Finished. Read and written 3011 packets to 5 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "prefix_malware_1 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-1-1/\"\n",
    "ps = PcapSplitter(prefix_malware_1 + \"2018-05-09-192.168.100.103.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.103\"\n",
    "!mkdir {prefix_malware_1}/splitted\n",
    "print(ps.split_by_session(prefix_malware_1 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "prefix_bening_1 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-4-1/\"\n",
    "ps = PcapSplitter(prefix_bening_1 + \"2018-10-25-14-06-32-192.168.1.132.pcap\")\n",
    "VICTIM_IP = \"192.168.1.132\"\n",
    "!mkdir {prefix_bening_1}/splitted\n",
    "print(ps.split_by_session(prefix_bening_1 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "prefix_bening_2 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-5-1/\"\n",
    "ps = PcapSplitter(prefix_bening_2 + \"2018-09-21-capture.pcap\")\n",
    "VICTIM_IP = \"192.168.2.3\"\n",
    "!mkdir -p {prefix_bening_2}/splitted\n",
    "print(ps.split_by_session(prefix_bening_2 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prefix_bening_3 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-7-1/Somfy-02/\"\n",
    "ps = PcapSplitter(prefix_bening_3 + \"2019-07-03-16-41-09-192.168.1.158.pcap\")\n",
    "VICTIM_IP = \"192.168.1.158\"\n",
    "!mkdir -p {prefix_bening_3}/splitted\n",
    "print(ps.split_by_session(prefix_bening_3 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prefix_malware_2 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-3-1/\"\n",
    "ps = PcapSplitter(prefix_malware_2 + \"2018-05-21_capture.pcap\")\n",
    "MALICIOUS_IP = \"192.168.2.5\"\n",
    "!mkdir {prefix_malware_2}/splitted\n",
    "print(ps.split_by_session(prefix_malware_2 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# To big to process...\n",
    "prefix_malware_3 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-7-1/\"\n",
    "ps = PcapSplitter(prefix_malware_3 + \"2018-07-20-17-31-20-192.168.100.108.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.108\"\n",
    "!mkdir  {prefix_malware_3}/splitted\n",
    "# print(ps.split_by_session(prefix_malware_3 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "prefix_malware_4 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-8-1/\"\n",
    "ps = PcapSplitter(prefix_malware_4 + \"2018-07-31-15-15-09-192.168.100.113.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.113\"\n",
    "!mkdir  {prefix_malware_4}/splitted\n",
    "print(ps.split_by_session(prefix_malware_4 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# NOT USED\n",
    "prefix_malware_5 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-9-1/\"\n",
    "ps = PcapSplitter(prefix_malware_5 + \"2018-07-25-10-53-16-192.168.100.111.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.111\"\n",
    "!mkdir  {prefix_malware_5}/splitted\n",
    "print(ps.split_by_session(prefix_malware_5 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "prefix_malware_6 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-17-1/\"\n",
    "ps = PcapSplitter(prefix_malware_6 + \"2018-09-06-11-43-12-192.168.100.111.only15000000.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.111\"\n",
    "!mkdir  {prefix_malware_6}/splitted\n",
    "print(ps.split_by_session(prefix_malware_6 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "prefix = prefix_bening_3\n",
    "useful_ip=VICTIM_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = prefix_bening_3\n",
    "useful_ip=VICTIM_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeek Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>tunnel_parents   label   detailed-label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-03 13:16:59.172194958</th>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>67</td>\n",
       "      <td>-   benign   -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03 13:17:29.173340082</th>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>68</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>67</td>\n",
       "      <td>-   benign   -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03 13:19:13.959669113</th>\n",
       "      <td>fe80::5bcc:698e:39d5:cdf</td>\n",
       "      <td>5353</td>\n",
       "      <td>ff02::fb</td>\n",
       "      <td>5353</td>\n",
       "      <td>-   benign   -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03 13:19:58.302953959</th>\n",
       "      <td>fe80::5bcc:698e:39d5:cdf</td>\n",
       "      <td>5353</td>\n",
       "      <td>ff02::fb</td>\n",
       "      <td>5353</td>\n",
       "      <td>-   benign   -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03 13:20:24.472592115</th>\n",
       "      <td>fe80::4eef:c0ff:fe27:561e</td>\n",
       "      <td>5353</td>\n",
       "      <td>ff02::fb</td>\n",
       "      <td>5353</td>\n",
       "      <td>-   benign   -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id.orig_h  id.orig_p  \\\n",
       "ts                                                                    \n",
       "2019-07-03 13:16:59.172194958                    0.0.0.0         68   \n",
       "2019-07-03 13:17:29.173340082            255.255.255.255         68   \n",
       "2019-07-03 13:19:13.959669113   fe80::5bcc:698e:39d5:cdf       5353   \n",
       "2019-07-03 13:19:58.302953959   fe80::5bcc:698e:39d5:cdf       5353   \n",
       "2019-07-03 13:20:24.472592115  fe80::4eef:c0ff:fe27:561e       5353   \n",
       "\n",
       "                                     id.resp_h  id.resp_p  \\\n",
       "ts                                                          \n",
       "2019-07-03 13:16:59.172194958  255.255.255.255         67   \n",
       "2019-07-03 13:17:29.173340082      192.168.1.1         67   \n",
       "2019-07-03 13:19:13.959669113         ff02::fb       5353   \n",
       "2019-07-03 13:19:58.302953959         ff02::fb       5353   \n",
       "2019-07-03 13:20:24.472592115         ff02::fb       5353   \n",
       "\n",
       "                              tunnel_parents   label   detailed-label  \n",
       "ts                                                                     \n",
       "2019-07-03 13:16:59.172194958                          -   benign   -  \n",
       "2019-07-03 13:17:29.173340082                          -   benign   -  \n",
       "2019-07-03 13:19:13.959669113                          -   benign   -  \n",
       "2019-07-03 13:19:58.302953959                          -   benign   -  \n",
       "2019-07-03 13:20:24.472592115                          -   benign   -  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas dataframe from a Zeek log\n",
    "log_to_df = LogToDataFrame()\n",
    "bro_df = log_to_df.create_dataframe(prefix + 'bro/conn.log.labeled', usecols = ['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'tunnel_parents   label   detailed-label'])\n",
    "\n",
    "# Print out the head of the dataframe\n",
    "bro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-   benign   -']\n",
       "Categories (1, object): ['-   benign   -']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bro_df['tunnel_parents   label   detailed-label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bro_df.groupby('tunnel_parents   label   detailed-label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filered_df = bro_df[bro_df['tunnel_parents   label   detailed-label']=='-   benign   -']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Pcap Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell would take many ours to complete. However, it can be interrupted at any time. If the subsequent cells are the runned, the work done so far will be saved in disk by file moving... \n",
    "\n",
    "If we need more data, we can get it by running this cells when we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doorlock_start = []\n",
    "echo = [] # Bening Victim Amazon Echo \n",
    "generic_cc = []\n",
    "cc_heartbeat = []\n",
    "okiru = []\n",
    "generic_ddos = []\n",
    "muhstik_botnet_file_names = []\n",
    "horizontal_scan_file_names = []\n",
    "bening_flow_file_names = []\n",
    "\n",
    "for idx, current_file_name in enumerate(files):\n",
    "    if idx%500==0:\n",
    "        print(f'{idx/len(files)}% done')\n",
    "    if idx>10000:\n",
    "        break\n",
    "    pcap_file = prefix + \"splitted/\" + current_file_name\n",
    "    useful_tuple = extract_fist_useful_tuple(\n",
    "        pcap_file=pcap_file,\n",
    "        useful_ip=useful_ip)\n",
    "    \n",
    "    if useful_tuple is not None:\n",
    "        \n",
    "        match = filered_df[(filered_df['id.orig_h']==useful_tuple[0]) &\\\n",
    "            (filered_df['id.orig_p']==useful_tuple[1]) &\\\n",
    "                (filered_df['id.resp_h']==useful_tuple[2]) &\\\n",
    "                    (filered_df['id.resp_p']==useful_tuple[3])] \n",
    "        \n",
    "        if len(match)>=1:\n",
    "            if len(match['tunnel_parents   label   detailed-label'].unique()) > 1:\n",
    "                print('discarding ambiguous 5-tuple')\n",
    "\n",
    "            label = match['tunnel_parents   label   detailed-label'].iloc[0]\n",
    "\n",
    "            if '-   benign   -' in label:\n",
    "                doorlock_start.append(current_file_name)\n",
    "            elif 'Malicious   Okiru' in label:\n",
    "                okiru.append(current_file_name)\n",
    "            elif 'Malicious   DDoS' in label:\n",
    "                generic_ddos.append(current_file_name)\n",
    "            elif 'C&C-HeartBeat' in label:\n",
    "                cc_heartbeat.append(current_file_name)\n",
    "            elif 'Malicious   Attack' in label:\n",
    "                muhstik_botnet_file_names.append(current_file_name)\n",
    "            elif 'Horizontal' in label:\n",
    "                horizontal_scan_file_names.append(current_file_name)\n",
    "            elif 'Malicious   C&C' in label:\n",
    "                generic_cc.append(current_file_name)\n",
    "            else:\n",
    "                bening_flow_file_names.append(current_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(doorlock_start))\n",
    "print(len(okiru))\n",
    "print(len(generic_ddos))\n",
    "print(len(cc_heartbeat))\n",
    "\n",
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(generic_cc))\n",
    "print(len(muhstik_botnet_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1761.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!mkdir -p {prefix}/okiru\n",
    "!mkdir -p {prefix}/generic_ddos\n",
    "!mkdir -p {prefix}/cc_heartbeat\n",
    "\n",
    "!mkdir -p {prefix}/h_scan\n",
    "!mkdir -p {prefix}/bening_traffic\n",
    "!mkdir -p {prefix}/generic_cc\n",
    "!mkdir -p {prefix}/muhstik\n",
    "\"\"\"\n",
    "\n",
    "!mkdir -p {prefix}/doorlock_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files(doorlock_start, prefix + \"splitted\", prefix + \"doorlock_start\")\n",
    "\n",
    "move_files(okiru, prefix + \"splitted\", prefix + \"okiru\")\n",
    "move_files(generic_ddos, prefix + \"splitted\", prefix + \"generic_ddos\")\n",
    "move_files(cc_heartbeat, prefix + \"splitted\", prefix + \"cc_heartbeat\")\n",
    "\n",
    "move_files(horizontal_scan_file_names, prefix + \"splitted\", prefix + \"h_scan\")\n",
    "move_files(bening_flow_file_names, prefix + \"splitted\", prefix + \"bening_traffic\")\n",
    "move_files(generic_cc, prefix + \"splitted\", prefix + \"generic_cc\")\n",
    "move_files(muhstik_botnet_file_names, prefix + \"splitted\", prefix + \"muhstik\")\n",
    "\n",
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "doorlock_start_file_names = list_files_in_directory(prefix + \"doorlock_start\")\n",
    "\"\"\"\n",
    "horizontal_scan_file_names = list_files_in_directory(prefix + \"horizontal_scan_flows\")\n",
    "bening_flow_file_names = list_files_in_directory(prefix + \"bening_flows\")\n",
    "command_and_conquer_file_names = list_files_in_directory(prefix + \"cc_flows\")\n",
    "muhstik_botnet_file_names = list_files_in_directory(prefix + \"muhstik_botnet_flows\")\n",
    "\n",
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(command_and_conquer_file_names))\n",
    "print(len(muhstik_botnet_file_names))\n",
    "\"\"\"\n",
    "print(len(doorlock_start_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where did we get the attacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## malicious:\n",
    "\n",
    "- bening_traffic (for attacker) and h_scan came from capture1-1\n",
    "- muhstik from capture 3-1\n",
    "- okiru, cc_heartbeat and generic_ddos from capture 7-1\n",
    "\n",
    "## bening:\n",
    "\n",
    "- hue from honeypot-4-1\n",
    "- echo from honeypot-5-1\n",
    "- doorlock from honeypot-7-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gns3_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
