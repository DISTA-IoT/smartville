{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcap_splitter.splitter import PcapSplitter\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import zat\n",
    "import shutil\n",
    "\n",
    "from zat.log_to_dataframe import LogToDataFrame\n",
    "import numpy as np\n",
    "from scapy.all import rdpcap\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            file_list.append(filename)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "\n",
    "def extract_5_tuple(pcap_file):\n",
    "    tuples = set()  # Using a set to ensure unique tuples\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            tuples.add(tuple_info)\n",
    "\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def extract_fist_useful_tuple(pcap_file, useful_ip):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    # print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            if not hasattr(transport_layer, 'sport'):\n",
    "                continue\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            if src_ip == useful_ip:\n",
    "                return tuple_info\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def move_files(file_list, source_folder, destination_folder):\n",
    "    for file_name in file_list:\n",
    "        source_file = os.path.join(source_folder, file_name)\n",
    "        destination_file = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.move(source_file, destination_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: {file_name} not found in {source_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while moving {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good to print out versions of stuff\n",
    "print('zat: {:s}'.format(zat.__version__))\n",
    "print('Pandas: {:s}'.format(pd.__version__))\n",
    "print('Numpy: {:s}'.format(np.__version__))\n",
    "print('Scikit Learn Version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting by flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2102.90s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started...\n",
      "Finished. Read and written 30012 packets to 16 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "prefix_malware_1 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-1-1/\"\n",
    "ps = PcapSplitter(prefix_malware_1 + \"2018-05-09-192.168.100.103.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.103\"\n",
    "!mkdir {prefix_malware_1}/splitted\n",
    "print(ps.split_by_session(prefix_malware_1 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "prefix_bening_1 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-4-1/\"\n",
    "ps = PcapSplitter(prefix_bening_1 + \"2018-10-25-14-06-32-192.168.1.132.pcap\")\n",
    "VICTIM_IP = \"192.168.1.132\"\n",
    "!mkdir {prefix_bening_1}/splitted\n",
    "print(ps.split_by_session(prefix_bening_1 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "prefix_bening_2 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-5-1/\"\n",
    "ps = PcapSplitter(prefix_bening_2 + \"2018-09-21-capture.pcap\")\n",
    "VICTIM_IP = \"192.168.2.3\"\n",
    "!mkdir -p {prefix_bening_2}/splitted\n",
    "print(ps.split_by_session(prefix_bening_2 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prefix_bening_3 = \"../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-7-1/Somfy-03/\"\n",
    "ps = PcapSplitter(prefix_bening_3 + \"2019-07-04-16-41-10-192.168.1.158.pcap\")\n",
    "VICTIM_IP = \"192.168.1.158\"\n",
    "!mkdir -p {prefix_bening_3}/splitted\n",
    "print(ps.split_by_session(prefix_bening_3 + \"splitted\", pkts_bpf_filter=f\"src host {VICTIM_IP}\"))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prefix_malware_2 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-3-1/\"\n",
    "ps = PcapSplitter(prefix_malware_2 + \"2018-05-21_capture.pcap\")\n",
    "MALICIOUS_IP = \"192.168.2.5\"\n",
    "!mkdir {prefix_malware_2}/splitted\n",
    "print(ps.split_by_session(prefix_malware_2 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# To big to process...\n",
    "prefix_malware_3 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-7-1/\"\n",
    "ps = PcapSplitter(prefix_malware_3 + \"2018-07-20-17-31-20-192.168.100.108.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.108\"\n",
    "!mkdir  {prefix_malware_3}/splitted\n",
    "# print(ps.split_by_session(prefix_malware_3 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "prefix_malware_4 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-8-1/\"\n",
    "ps = PcapSplitter(prefix_malware_4 + \"2018-07-31-15-15-09-192.168.100.113.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.113\"\n",
    "!mkdir  {prefix_malware_4}/splitted\n",
    "print(ps.split_by_session(prefix_malware_4 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# NOT USED\n",
    "prefix_malware_5 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-9-1/\"\n",
    "ps = PcapSplitter(prefix_malware_5 + \"2018-07-25-10-53-16-192.168.100.111.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.111\"\n",
    "!mkdir  {prefix_malware_5}/splitted\n",
    "print(ps.split_by_session(prefix_malware_5 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "prefix_malware_6 = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-17-1/\"\n",
    "ps = PcapSplitter(prefix_malware_6 + \"2018-09-06-11-43-12-192.168.100.111.only15000000.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.111\"\n",
    "!mkdir  {prefix_malware_6}/splitted\n",
    "print(ps.split_by_session(prefix_malware_6 + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))\n",
    "\"\"\"\n",
    "\n",
    "prefix = prefix_bening_3\n",
    "useful_ip=VICTIM_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = prefix_bening_3\n",
    "useful_ip=VICTIM_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeek Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not read/access zeek log file: ../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-7-1/Somfy-02/bro/conn.log.labeled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a Pandas dataframe from a Zeek log\u001b[39;00m\n\u001b[1;32m      2\u001b[0m log_to_df \u001b[38;5;241m=\u001b[39m LogToDataFrame()\n\u001b[0;32m----> 3\u001b[0m bro_df \u001b[38;5;241m=\u001b[39m \u001b[43mlog_to_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbro/conn.log.labeled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid.orig_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid.orig_p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid.resp_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid.resp_p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtunnel_parents   label   detailed-label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print out the head of the dataframe\u001b[39;00m\n\u001b[1;32m      6\u001b[0m bro_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Projects/GNS3_TESI/gns3_thesis/lib/python3.10/site-packages/zat/log_to_dataframe.py:60\u001b[0m, in \u001b[0;36mLogToDataFrame.create_dataframe\u001b[0;34m(self, log_filename, ts_index, aggressive_category, usecols)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Create a Pandas dataframe from a Bro/Zeek log file\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m       log_fllename (string): The full path to the Zeek log\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m       usecol (list): A subset of columns to read in (minimizes memory usage) (default = None)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Grab the field information\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m field_names, field_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_field_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m all_fields \u001b[38;5;241m=\u001b[39m field_names  \u001b[38;5;66;03m# We need ALL the fields for later\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# If usecols is set then we'll subset the fields and types\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/GNS3_TESI/gns3_thesis/lib/python3.10/site-packages/zat/log_to_dataframe.py:42\u001b[0m, in \u001b[0;36mLogToDataFrame._get_field_info\u001b[0;34m(self, log_filename)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_field_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, log_filename):\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal Method: Use ZAT log reader to read header for names and types\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     _zeek_reader \u001b[38;5;241m=\u001b[39m \u001b[43mzeek_log_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZeekLogReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     _, field_names, field_types, _ \u001b[38;5;241m=\u001b[39m _zeek_reader\u001b[38;5;241m.\u001b[39m_parse_zeek_header(log_filename)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m field_names, field_types\n",
      "File \u001b[0;32m~/Projects/GNS3_TESI/gns3_thesis/lib/python3.10/site-packages/zat/zeek_log_reader.py:36\u001b[0m, in \u001b[0;36mZeekLogReader.__init__\u001b[0;34m(self, filepath, delimiter, tail, strict)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# First check if the file exists and is readable\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(filepath, os\u001b[38;5;241m.\u001b[39mR_OK):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not read/access zeek log file: \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filepath))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Setup some class instance vars\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filepath \u001b[38;5;241m=\u001b[39m filepath\n",
      "\u001b[0;31mOSError\u001b[0m: Could not read/access zeek log file: ../../../Downloads/iot_23_datasets_full/CTU-Honeypot-Capture-7-1/Somfy-02/bro/conn.log.labeled"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe from a Zeek log\n",
    "log_to_df = LogToDataFrame()\n",
    "bro_df = log_to_df.create_dataframe(prefix + 'bro/conn.log.labeled', usecols = ['id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'tunnel_parents   label   detailed-label'])\n",
    "\n",
    "# Print out the head of the dataframe\n",
    "bro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-   benign   -']\n",
       "Categories (1, object): ['-   benign   -']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bro_df['tunnel_parents   label   detailed-label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bro_df.groupby('tunnel_parents   label   detailed-label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filered_df = bro_df[bro_df['tunnel_parents   label   detailed-label']=='-   benign   -']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Pcap Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell would take many ours to complete. However, it can be interrupted at any time. If the subsequent cells are the runned, the work done so far will be saved in disk by file moving... \n",
    "\n",
    "If we need more data, we can get it by running this cells when we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doorlock_start = []\n",
    "echo = [] # Bening Victim Amazon Echo \n",
    "generic_cc = []\n",
    "cc_heartbeat = []\n",
    "okiru = []\n",
    "generic_ddos = []\n",
    "muhstik_botnet_file_names = []\n",
    "horizontal_scan_file_names = []\n",
    "bening_flow_file_names = []\n",
    "\n",
    "for idx, current_file_name in enumerate(files):\n",
    "    if idx%500==0:\n",
    "        print(f'{idx/len(files)}% done')\n",
    "    if idx>10000:\n",
    "        break\n",
    "    pcap_file = prefix + \"splitted/\" + current_file_name\n",
    "    useful_tuple = extract_fist_useful_tuple(\n",
    "        pcap_file=pcap_file,\n",
    "        useful_ip=useful_ip)\n",
    "    \n",
    "    if useful_tuple is not None:\n",
    "        \n",
    "        match = filered_df[(filered_df['id.orig_h']==useful_tuple[0]) &\\\n",
    "            (filered_df['id.orig_p']==useful_tuple[1]) &\\\n",
    "                (filered_df['id.resp_h']==useful_tuple[2]) &\\\n",
    "                    (filered_df['id.resp_p']==useful_tuple[3])] \n",
    "        \n",
    "        if len(match)>=1:\n",
    "            if len(match['tunnel_parents   label   detailed-label'].unique()) > 1:\n",
    "                print('discarding ambiguous 5-tuple')\n",
    "\n",
    "            label = match['tunnel_parents   label   detailed-label'].iloc[0]\n",
    "\n",
    "            if '-   benign   -' in label:\n",
    "                doorlock_start.append(current_file_name)\n",
    "            elif 'Malicious   Okiru' in label:\n",
    "                okiru.append(current_file_name)\n",
    "            elif 'Malicious   DDoS' in label:\n",
    "                generic_ddos.append(current_file_name)\n",
    "            elif 'C&C-HeartBeat' in label:\n",
    "                cc_heartbeat.append(current_file_name)\n",
    "            elif 'Malicious   Attack' in label:\n",
    "                muhstik_botnet_file_names.append(current_file_name)\n",
    "            elif 'Horizontal' in label:\n",
    "                horizontal_scan_file_names.append(current_file_name)\n",
    "            elif 'Malicious   C&C' in label:\n",
    "                generic_cc.append(current_file_name)\n",
    "            else:\n",
    "                bening_flow_file_names.append(current_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(doorlock_start))\n",
    "print(len(okiru))\n",
    "print(len(generic_ddos))\n",
    "print(len(cc_heartbeat))\n",
    "\n",
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(generic_cc))\n",
    "print(len(muhstik_botnet_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1761.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!mkdir -p {prefix}/okiru\n",
    "!mkdir -p {prefix}/generic_ddos\n",
    "!mkdir -p {prefix}/cc_heartbeat\n",
    "\n",
    "!mkdir -p {prefix}/h_scan\n",
    "!mkdir -p {prefix}/bening_traffic\n",
    "!mkdir -p {prefix}/generic_cc\n",
    "!mkdir -p {prefix}/muhstik\n",
    "\"\"\"\n",
    "\n",
    "!mkdir -p {prefix}/doorlock_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files(doorlock_start, prefix + \"splitted\", prefix + \"doorlock_start\")\n",
    "\n",
    "move_files(okiru, prefix + \"splitted\", prefix + \"okiru\")\n",
    "move_files(generic_ddos, prefix + \"splitted\", prefix + \"generic_ddos\")\n",
    "move_files(cc_heartbeat, prefix + \"splitted\", prefix + \"cc_heartbeat\")\n",
    "\n",
    "move_files(horizontal_scan_file_names, prefix + \"splitted\", prefix + \"h_scan\")\n",
    "move_files(bening_flow_file_names, prefix + \"splitted\", prefix + \"bening_traffic\")\n",
    "move_files(generic_cc, prefix + \"splitted\", prefix + \"generic_cc\")\n",
    "move_files(muhstik_botnet_file_names, prefix + \"splitted\", prefix + \"muhstik\")\n",
    "\n",
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "doorlock_start_file_names = list_files_in_directory(prefix + \"doorlock_start\")\n",
    "\"\"\"\n",
    "horizontal_scan_file_names = list_files_in_directory(prefix + \"horizontal_scan_flows\")\n",
    "bening_flow_file_names = list_files_in_directory(prefix + \"bening_flows\")\n",
    "command_and_conquer_file_names = list_files_in_directory(prefix + \"cc_flows\")\n",
    "muhstik_botnet_file_names = list_files_in_directory(prefix + \"muhstik_botnet_flows\")\n",
    "\n",
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(command_and_conquer_file_names))\n",
    "print(len(muhstik_botnet_file_names))\n",
    "\"\"\"\n",
    "print(len(doorlock_start_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where did we get the attacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## malicious:\n",
    "\n",
    "- bening_traffic (for attacker) and h_scan came from capture1-1\n",
    "- muhstik from capture 3-1\n",
    "- okiru, cc_heartbeat and generic_ddos from capture 7-1\n",
    "\n",
    "## bening:\n",
    "\n",
    "- hue from honeypot-4-1\n",
    "- echo from honeypot-5-1\n",
    "- doorlock from honeypot-7-1 (Somfy-01, Somfy-02, and Somfy-03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gns3_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
