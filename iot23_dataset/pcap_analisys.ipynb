{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcap_splitter.splitter import PcapSplitter\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import zat\n",
    "import shutil\n",
    "\n",
    "from zat.log_to_dataframe import LogToDataFrame\n",
    "from zat.dataframe_to_matrix import DataFrameToMatrix\n",
    "import numpy as np\n",
    "from scapy.all import rdpcap\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            file_list.append(filename)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "\n",
    "def extract_5_tuple(pcap_file):\n",
    "    tuples = set()  # Using a set to ensure unique tuples\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            tuples.add(tuple_info)\n",
    "\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def extract_fist_useful_tuple(pcap_file, useful_ip):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    \n",
    "    # print(f\"found {len(packets)} packets in file\")\n",
    "\n",
    "    for idx, packet in enumerate(packets):\n",
    "        if idx>0 and idx%50==0:\n",
    "            print(\".\")\n",
    "        if packet.haslayer('IP'):\n",
    "            ip_layer = packet['IP']\n",
    "            transport_layer = packet[ip_layer.payload.name]\n",
    "\n",
    "            # Extracting the 5-tuple information\n",
    "            src_ip = ip_layer.src\n",
    "            dst_ip = ip_layer.dst\n",
    "            src_port = transport_layer.sport\n",
    "            dst_port = transport_layer.dport\n",
    "            proto = ip_layer.proto\n",
    "\n",
    "            # Forming the 5-tuple\n",
    "            tuple_info = (src_ip, src_port, dst_ip, dst_port, proto)\n",
    "            if src_ip == useful_ip:\n",
    "                return tuple_info\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def move_files(file_list, source_folder, destination_folder):\n",
    "    for file_name in file_list:\n",
    "        source_file = os.path.join(source_folder, file_name)\n",
    "        destination_file = os.path.join(destination_folder, file_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.move(source_file, destination_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: {file_name} not found in {source_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while moving {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good to print out versions of stuff\n",
    "print('zat: {:s}'.format(zat.__version__))\n",
    "print('Pandas: {:s}'.format(pd.__version__))\n",
    "print('Numpy: {:s}'.format(np.__version__))\n",
    "print('Scikit Learn Version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting by flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"../../../Downloads/iot_23_datasets_full/CTU-IoT-Malware-Capture-1-1/\"\n",
    "ps = PcapSplitter(prefix + \"2018-05-09-192.168.100.103.pcap\")\n",
    "MALICIOUS_IP = \"192.168.100.103\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps.split_by_session(prefix + \"splitted\", pkts_bpf_filter=f\"src host {MALICIOUS_IP}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeek Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas dataframe from a Zeek log\n",
    "log_to_df = LogToDataFrame()\n",
    "bro_df = log_to_df.create_dataframe(prefix + 'bro/conn.log.labeled')\n",
    "\n",
    "# Print out the head of the dataframe\n",
    "bro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bro_df['tunnel_parents   label   detailed-label'.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bro_df.groupby('tunnel_parents   label   detailed-label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Pcap Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell would take many ours to complete. However, it can be interrupted at any time. If the subsequent cells are the runned, the work done so far will be saved in disk by file moving... \n",
    "\n",
    "If we need more data, we can get it by running this cells when we want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_scan_file_names = []\n",
    "command_and_conquer_file_names = []\n",
    "bening_flow_file_names = []\n",
    "\n",
    "for idx, current_file_name in enumerate(files):\n",
    "    if idx%500==0:\n",
    "        print(f'{idx/len(files)}% done')\n",
    "        \n",
    "    pcap_file = prefix + \"splitted/\" + current_file_name\n",
    "    useful_tuple = extract_fist_useful_tuple(\n",
    "        pcap_file=pcap_file,\n",
    "        useful_ip=\"192.168.100.103\")\n",
    "    if useful_tuple is not None:\n",
    "        match = bro_df[(bro_df['id.orig_h']==useful_tuple[0]) &\\\n",
    "            (bro_df['id.orig_p']==useful_tuple[1]) &\\\n",
    "                (bro_df['id.resp_h']==useful_tuple[2]) &\\\n",
    "                    (bro_df['id.resp_p']==useful_tuple[3])] \n",
    "        if len(match)>1:\n",
    "            if len(match['tunnel_parents   label   detailed-label'].unique()) > 1:\n",
    "                print('discarding ambiguous 5-tuple')\n",
    "\n",
    "            label = match['tunnel_parents   label   detailed-label'].iloc[0]\n",
    "\n",
    "            if 'Horizontal' in label:\n",
    "                horizontal_scan_file_names.append(current_file_name)\n",
    "            elif 'C&C' in label:\n",
    "                command_and_conquer_file_names.append(current_file_name)\n",
    "            else:\n",
    "                bening_flow_file_names.append(current_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4122\n",
      "329\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(command_and_conquer_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files(horizontal_scan_file_names, prefix + \"splitted\", prefix + \"horizontal_scan_flows\")\n",
    "move_files(bening_flow_file_names, prefix + \"splitted\", prefix + \"bening_flows\")\n",
    "move_files(command_and_conquer_file_names, prefix + \"splitted\", prefix + \"cc_flows\")\n",
    "files = list_files_in_directory(prefix + \"splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7978\n",
      "671\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "horizontal_scan_file_names = list_files_in_directory(prefix + \"horizontal_scan_flows\")\n",
    "bening_flow_file_names = list_files_in_directory(prefix + \"bening_flows\")\n",
    "command_and_conquer_file_names = list_files_in_directory(prefix + \"cc_flows\")\n",
    "print(len(horizontal_scan_file_names))\n",
    "print(len(bening_flow_file_names))\n",
    "print(len(command_and_conquer_file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gns3_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
